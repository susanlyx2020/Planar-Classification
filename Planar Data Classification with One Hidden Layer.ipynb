{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c9ddf7-5311-4df4-8c70-f78a35d1929e",
   "metadata": {},
   "source": [
    "# Pakcages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8359efbd-d677-49f9-b541-e99597c790f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'testCases_v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtestCases_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpublic_tests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'testCases_v2'"
     ]
    }
   ],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases_v2 import *\n",
    "from public_tests import *\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48df89cc-72ae-420f-97eb-abf22dbae6d4",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b56207d-b4ae-4e03-8dd9-fef0eb4b33d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_planar_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mload_planar_dataset\u001b[49m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Visualize the data:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(X[\u001b[38;5;241m0\u001b[39m, :], X[\u001b[38;5;241m1\u001b[39m, :], c\u001b[38;5;241m=\u001b[39mY, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mSpectral);\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_planar_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "X, Y = load_planar_dataset()\n",
    "\n",
    "# Visualize the data:\n",
    "plt.scatter(X[0, :], X[1, :], c=Y, s=40, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b8a7f-be1e-4341-b0dd-c77eaa3baf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many training examples are there?\n",
    "shape_X = np.shape(X)\n",
    "shape_Y = np.shape(Y)\n",
    "m = shape_X[1]\n",
    "\n",
    "\n",
    "print ('The shape of X is: ' + str(shape_X))\n",
    "print ('The shape of Y is: ' + str(shape_Y))\n",
    "print ('I have m = %d training examples!' % (m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b96fa6d-8fbe-4360-bc0b-e4042e67a637",
   "metadata": {},
   "source": [
    "## Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617f890-5699-4598-9cfb-62f111710ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression classifier\n",
    "clf = sklearn.linear_model.LogisticRegressionCV();\n",
    "clf.fit(X.T, Y.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720259cd-420d-4615-815a-930c217be0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundary for logistic regression\n",
    "plot_decision_boundary(lambda x: clf.predict(x), X, Y)\n",
    "plt.title(\"Logistic Regression\")\n",
    "\n",
    "# Print accuracy\n",
    "LR_predictions = clf.predict(X.T)\n",
    "print ('Accuracy of logistic regression: %d ' % float((np.dot(Y,LR_predictions) + np.dot(1-Y,1-LR_predictions))/float(Y.size)*100) +\n",
    "       '% ' + \"(percentage of correctly labelled datapoints)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b82a18-a3e5-49c3-980a-d443c3faa9ab",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23035b-8a16-4c81-96c6-15ef26459e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Neural net structure\n",
    "def layer_sizes(X, Y):\n",
    "    n_x = X.shape[0]\n",
    "    n_h = 4\n",
    "    n_y = Y.shape[0]\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    return (n_x, n_h, n_y)\n",
    "\n",
    "t_X, t_Y = layer_sizes_test_case()\n",
    "(n_x, n_h, n_y) = layer_sizes(t_X, t_Y)\n",
    "print(\"The size of the input layer is: n_x = \" + str(n_x))\n",
    "print(\"The size of the hidden layer is: n_h = \" + str(n_h))\n",
    "print(\"The size of the output layer is: n_y = \" + str(n_y))\n",
    "\n",
    "layer_sizes_test(layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5385e3-8ae8-4d86-a1ba-154471399e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model's parameter\n",
    "def initialize_parameters(n_x, n_h, n_y):  \n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n",
    "    \n",
    "np.random.seed(2)\n",
    "n_x, n_h, n_y = initialize_parameters_test_case()\n",
    "parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "\n",
    "initialize_parameters_test(initialize_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5d07f-9888-4f62-b292-4d342dec1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing forward propogation\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache\n",
    "    \n",
    "t_X, parameters = forward_propagation_test_case()\n",
    "A2, cache = forward_propagation(t_X, parameters)\n",
    "print(\"A2 = \" + str(A2))\n",
    "\n",
    "forward_propagation_test(forward_propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8289742d-c149-486d-afb0-6ef08de3bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing cross entropy loss \n",
    "def compute_cost(A2, Y):\n",
    "    m = Y.shape[1] # number of examples\n",
    "\n",
    "    logprobs = np.multiply(Y, np.log(A2)) + np.multiply(1 - Y, np.log(1 - A2))\n",
    "    cost = - np.sum(logprobs) / m\n",
    "\n",
    "    \n",
    "    cost = float(np.squeeze(cost)) \n",
    "    \n",
    "    return cost\n",
    "\n",
    "A2, t_Y = compute_cost_test_case()\n",
    "cost = compute_cost(A2, t_Y)\n",
    "print(\"cost = \" + str(compute_cost(A2, t_Y)))\n",
    "\n",
    "compute_cost_test(compute_cost)2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683c862-5051-448c-ae3f-2836a143bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing backpropagation\n",
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    m = X.shape[1]\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2, A1.T) / m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n",
    "    dW1 = np.dot(dZ1, X.T) / m\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads\n",
    "\n",
    "parameters, cache, t_X, t_Y = backward_propagation_test_case()\n",
    "\n",
    "grads = backward_propagation(parameters, cache, t_X, t_Y)\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
    "print (\"db2 = \"+ str(grads[\"db2\"]))\n",
    "\n",
    "backward_propagation_test(backward_propagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe4346-cf94-4bf0-8e07-6ab30a709d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gradient descent to update the parameters\n",
    "def update_parameters(parameters, grads, learning_rate = 1.2):\n",
    "    param = copy.deepcopy(parameters)\n",
    "    W1 = param['W1']\n",
    "    b1 = param['b1']\n",
    "    W2 = param['W2']\n",
    "    b2 = param['b2']\n",
    "\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n",
    "    \n",
    "parameters, grads = update_parameters_test_case()\n",
    "parameters = update_parameters(parameters, grads)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))\n",
    "\n",
    "update_parameters_test(update_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c553f44-8f69-49e1-b59e-e74e32bdc676",
   "metadata": {},
   "source": [
    "## Integrating the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0a98d1-5d51-4d54-85d6-aca1eb07dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural net\n",
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "\n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "\n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    "        parameters = update_parameters(parameters, grads)\n",
    "\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters\n",
    "nn_model_test(nn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16acf3b-f48a-4e98-b6ec-3287849b5ac8",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cb2db-421a-4336-8f02-82ab4823091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using forward propagation to predict results.\n",
    "def predict(parameters, X):\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = (A2 > 0.5).astype(int)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5566a8dd-5986-4775-a830-53067457f60a",
   "metadata": {},
   "source": [
    "## Model Testing\n",
    "Test the Model on the Planar Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe40d54-e09c-4844-843d-c2a4ad8f7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a model with a n_h-dimensional hidden layer\n",
    "parameters = nn_model(X, Y, n_h = 4, num_iterations = 10000, print_cost=True)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plot_decision_boundary(lambda x: predict(parameters, x.T), X, Y)\n",
    "plt.title(\"Decision Boundary for hidden layer size \" + str(4))\n",
    "\n",
    "# Print accuracy\n",
    "predictions = predict(parameters, X)\n",
    "print ('Accuracy: %d' % float((np.dot(Y, predictions.T) + np.dot(1 - Y, 1 - predictions.T)) / float(Y.size) * 100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
